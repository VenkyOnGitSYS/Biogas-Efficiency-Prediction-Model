{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "98fc12bd-9c4a-4b38-9baa-eecd1041c904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² score: 1.00\n",
      "MSE: 0.15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['biogas_efficiency_model.pkl']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib  \n",
    "\n",
    "def gaussian_score(value, optimal, spread):\n",
    "    return math.exp(-((value - optimal) ** 2) / (2 * spread ** 2))\n",
    "\n",
    "def compute_efficiency(temp, humidity, methane):\n",
    "    temp_score = gaussian_score(temp, 37.5, 3) #can be between 20 and 45 deg cel for anaerobic processes , 37.5 for convenience\n",
    "    humidity_score = gaussian_score(humidity, 60, 10) #can go upto 100 % for high fermentation rates\n",
    "    methane_score = gaussian_score(methane, 800, 150) #can be upto 75 % of the biogas, for in this case we take 800\n",
    "    return round((temp_score * 0.4 + humidity_score * 0.3 + methane_score * 0.3) * 100, 2)\n",
    "\n",
    "# Step 1: Load data from the CSV file\n",
    "df = pd.read_csv('full_sensor_data.csv')\n",
    "\n",
    "if not all(col in df.columns for col in ['temperature', 'humidity', 'mq2_value']):\n",
    "    raise ValueError(\"CSV file must contain 'temperature', 'humidity', and 'mq2_value' columns\")\n",
    "\n",
    "# Step 2: Calculate efficiency based on the existing data\n",
    "df['efficiency'] = df.apply(lambda row: compute_efficiency(row['temperature'], row['humidity'], row['mq2_value']), axis=1)\n",
    "\n",
    "# Step 3: Train model\n",
    "X = df[['temperature', 'humidity', 'mq2_value']]  # Features\n",
    "y = df['efficiency']  # Target (efficiency)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize RandomForestRegressor model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"R² score: {r2_score(y_test, y_pred):.2f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred):.2f}\")\n",
    "\n",
    "# Step 5: Save the trained model\n",
    "joblib.dump(model, 'biogas_efficiency_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8975243a-214a-4a72-8648-c8121bf6c3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Efficiency: 18.31%\n"
     ]
    }
   ],
   "source": [
    "predicted_efficiency = compute_efficiency(51, 50.0, 300.0)\n",
    "print(f\"Predicted Efficiency: {predicted_efficiency:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4e914668-7546-415a-b922-745d45614aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Efficiency: 60.49%\n"
     ]
    }
   ],
   "source": [
    "temperature = 42\n",
    "humidity = 67\n",
    "methane = 900\n",
    "\n",
    "efficiency = compute_efficiency(temperature, humidity, methane)\n",
    "print(f\"Predicted Efficiency: {efficiency:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c791baf0-5e7f-42bb-982d-4536595b993e",
   "metadata": {},
   "source": [
    "now we have the model using a gaussian model, it is important to explain how exactly the predictions are going to work.\n",
    "\n",
    "we can say that this model is absolutely perfect with its r2_score of 1.00, which means any and all variance is easily explained without any hitches.\n",
    "with this in mind, the predictions will work every 2 hours, with the django api adding new entries that will serve as additional training and testing data in the csv file ; which once configured properly , can provide an accordingly appropriate prediction every 2 hours on the efficiency of the biogas produced in the temperature, humidity and the methane ppm levels within the system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617930b1-658b-4301-8809-ca03a2d72093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
